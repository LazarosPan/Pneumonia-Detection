{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lazaros/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import os\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "import torch\n",
    "from PIL import Image\n",
    "import multiprocessing\n",
    "\n",
    "num_cpu_cores = multiprocessing.cpu_count()\n",
    "num_cpu_cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_id\n",
      "1    7762\n",
      "0    8773\n",
      "2    8793\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# to read .csv files from another directory\n",
    "location = \"detect-pneumonia-spring-2024/\" # \"/<path>\"\n",
    "\n",
    "df = pd.read_csv(location + \"labels_train.csv\")\n",
    "\n",
    "# Get the count of images in each class\n",
    "class_counts = df['class_id'].value_counts()\n",
    "\n",
    "# Define the target number of images per class\n",
    "target_images_per_class = 10000\n",
    "\n",
    "# Calculate the number of additional images needed for each class\n",
    "additional_images_needed = target_images_per_class - class_counts\n",
    "print(additional_images_needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>class_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img_4358977458434011046.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img_5224016757187192130.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img_3065202206106254707.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img_6304894865561547174.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img_3371338542810939877.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4667</th>\n",
       "      <td>img_6661311872293090412.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4668</th>\n",
       "      <td>img_3844568579349757418.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4669</th>\n",
       "      <td>img_9145812369383814369.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4670</th>\n",
       "      <td>img_1311393330250392648.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4671</th>\n",
       "      <td>img_3089041144907674826.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4672 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        file_name  class_id\n",
       "0     img_4358977458434011046.jpg         1\n",
       "1     img_5224016757187192130.jpg         2\n",
       "2     img_3065202206106254707.jpg         2\n",
       "3     img_6304894865561547174.jpg         1\n",
       "4     img_3371338542810939877.jpg         2\n",
       "...                           ...       ...\n",
       "4667  img_6661311872293090412.jpg         2\n",
       "4668  img_3844568579349757418.jpg         1\n",
       "4669  img_9145812369383814369.jpg         1\n",
       "4670  img_1311393330250392648.jpg         1\n",
       "4671  img_3089041144907674826.jpg         1\n",
       "\n",
       "[4672 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 224, 224]) torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "# Define the augmentation function using OpenCV\n",
    "def augment_image(image):\n",
    "    # Random rotation\n",
    "    angle = np.random.uniform(-10, 10)\n",
    "    M = cv2.getRotationMatrix2D((image.shape[1] // 2, image.shape[0] // 2), angle, 1)\n",
    "    image = cv2.warpAffine(image, M, (image.shape[1], image.shape[0]))\n",
    "\n",
    "    # Random width and height shift\n",
    "    tx = np.random.uniform(-0.1, 0.1) * image.shape[1]\n",
    "    ty = np.random.uniform(-0.1, 0.1) * image.shape[0]\n",
    "    M = np.float32([[1, 0, tx], [0, 1, ty]])\n",
    "    image = cv2.warpAffine(image, M, (image.shape[1], image.shape[0]))\n",
    "\n",
    "    # Random shear\n",
    "    shear_factor = np.random.uniform(-0.2, 0.2)\n",
    "    M = np.float32([[1, shear_factor, 0], [0, 1, 0]])\n",
    "    image = cv2.warpAffine(image, M, (image.shape[1], image.shape[0]))\n",
    "\n",
    "    # Random zoom\n",
    "    zx, zy = np.random.uniform(0.9, 1.1, 2)\n",
    "    image = cv2.resize(image, None, fx=zx, fy=zy, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    # Random horizontal flip\n",
    "    if np.random.rand() < 0.5:\n",
    "        image = cv2.flip(image, 1)\n",
    "    \n",
    "    return image\n",
    "\n",
    "# Define the custom dataset\n",
    "class PneumoniaDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None, target_images_per_class=10000):\n",
    "        self.annotations = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.target_images_per_class = target_images_per_class\n",
    "        \n",
    "        # Calculate the number of images needed for each class\n",
    "        self.class_counts = self.annotations['class_id'].value_counts()\n",
    "        self.additional_images_needed = target_images_per_class - self.class_counts\n",
    "\n",
    "        # Create lists of images per class\n",
    "        self.image_paths_by_class = {class_id: [] for class_id in self.additional_images_needed.index}\n",
    "        for idx, row in self.annotations.iterrows():\n",
    "            self.image_paths_by_class[row['class_id']].append(row['file_name'])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.target_images_per_class * len(self.additional_images_needed)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Determine the class and the specific image index within that class\n",
    "        class_id = idx // self.target_images_per_class\n",
    "        img_idx = idx % self.target_images_per_class\n",
    "        \n",
    "        if img_idx < self.class_counts[class_id]:\n",
    "            # Original image\n",
    "            img_name = self.image_paths_by_class[class_id][img_idx]\n",
    "            img_path = os.path.join(self.root_dir, img_name)\n",
    "            image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        else:\n",
    "            # Augmented image\n",
    "            img_name = np.random.choice(self.image_paths_by_class[class_id])\n",
    "            img_path = os.path.join(self.root_dir, img_name)\n",
    "            image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            image = augment_image(image)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        label = class_id\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Create the dataset and dataloader\n",
    "dataset = PneumoniaDataset(\n",
    "    csv_file= location + 'labels_train.csv',\n",
    "    root_dir= location + 'train_images/train_images',\n",
    "    transform=transform,\n",
    "    target_images_per_class=10000\n",
    ")\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers= num_cpu_cores)\n",
    "\n",
    "# Example of iterating through the dataloader\n",
    "for images, labels in dataloader:\n",
    "    print(images.shape, labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def augment_image(image):\n",
    "#     # Random rotation\n",
    "#     angle = np.random.uniform(-10, 10)\n",
    "#     M = cv2.getRotationMatrix2D((image.shape[1] // 2, image.shape[0] // 2), angle, 1)\n",
    "#     image = cv2.warpAffine(image, M, (image.shape[1], image.shape[0]))\n",
    "\n",
    "#     # Random width and height shift\n",
    "#     tx = np.random.uniform(-0.1, 0.1) * image.shape[1]\n",
    "#     ty = np.random.uniform(-0.1, 0.1) * image.shape[0]\n",
    "#     M = np.float32([[1, 0, tx], [0, 1, ty]])\n",
    "#     image = cv2.warpAffine(image, M, (image.shape[1], image.shape[0]))\n",
    "\n",
    "#     # Random shear\n",
    "#     shear_factor = np.random.uniform(-0.2, 0.2)\n",
    "#     M = np.float32([[1, shear_factor, 0], [0, 1, 0]])\n",
    "#     image = cv2.warpAffine(image, M, (image.shape[1], image.shape[0]))\n",
    "\n",
    "#     # Random zoom\n",
    "#     zx, zy = np.random.uniform(0.9, 1.1, 2)\n",
    "#     image = cv2.resize(image, None, fx=zx, fy=zy, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "#     # Random horizontal flip\n",
    "#     if np.random.rand() < 0.5:\n",
    "#         image = cv2.flip(image, 1)\n",
    "    \n",
    "#     return image\n",
    "\n",
    "\n",
    "# def resize_image(image, target_width=224, target_height=224):\n",
    "#     return cv2.resize(image, (target_width, target_height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class PneumoniaDataset(Dataset):\n",
    "#     def __init__(self, csv_file, root_dir, transform=None):\n",
    "#         self.annotations = pd.read_csv(csv_file)\n",
    "#         self.root_dir = root_dir\n",
    "#         self.transform = transform\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.annotations)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         img_name = os.path.join(self.root_dir, self.annotations.iloc[idx, 0])\n",
    "#         image = cv2.imread(img_name, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "#         if self.transform:\n",
    "#             image = self.transform(image)\n",
    "        \n",
    "#         # Convert image to 3-channel (if necessary) for pre-trained models\n",
    "#         image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "#         image = resize_image(image)\n",
    "        \n",
    "#         label = int(self.annotations.iloc[idx, 1])\n",
    "#         image = torch.tensor(image, dtype=torch.float32).permute(2, 0, 1) / 255.0\n",
    "        \n",
    "#         return image, label\n",
    "\n",
    "# def augment_and_resize(image):\n",
    "#     augmented_image = augment_image(image)\n",
    "#     resized_image = resize_image(augmented_image)\n",
    "#     return resized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Apply transformations using the function\n",
    "# dataset = PneumoniaDataset(csv_file= location +'labels_train.csv', \n",
    "#                            root_dir= location + 'train_images', \n",
    "#                            transform=augment_and_resize)\n",
    "\n",
    "# dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PneumoniaModel(pl.LightningModule):\n",
    "    def __init__(self, num_classes=3):\n",
    "        super(PneumoniaModel, self).__init__()\n",
    "        self.model = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "        self.model.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "        outputs = self(images)\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return Adam(self.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "2024-05-27 20:33:51.380903: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-27 20:33:51.385197: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-27 20:33:51.424448: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-27 20:33:52.436680: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\n",
      "  | Name  | Type   | Params\n",
      "---------------------------------\n",
      "0 | model | ResNet | 23.5 M\n",
      "---------------------------------\n",
      "23.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.032    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:  54%|█████▍    | 510/938 [38:52<32:37,  0.22it/s, v_num=4]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lazaros/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    }
   ],
   "source": [
    "model = PneumoniaModel()\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=10, accelerator='dp') if torch.cuda.is_available() else pl.Trainer(max_epochs=10)\n",
    "trainer.fit(model, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the directory and file name to save the model\n",
    "model_save_path = location + \"models/pneumonia_model_v1.pth\"\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), model_save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'collections.OrderedDict' object has no attribute 'eval'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file_name \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(test_folder):\n\u001b[1;32m     27\u001b[0m     image_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(test_folder, file_name)\n\u001b[0;32m---> 28\u001b[0m     predicted_label \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m     predictions\u001b[38;5;241m.\u001b[39mappend(predicted_label)\n\u001b[1;32m     30\u001b[0m     file_names\u001b[38;5;241m.\u001b[39mappend(file_name)\n",
      "Cell \u001b[0;32mIn[11], line 11\u001b[0m, in \u001b[0;36mpredict_image\u001b[0;34m(model, image_path, transform)\u001b[0m\n\u001b[1;32m      9\u001b[0m image \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(image_path)\n\u001b[1;32m     10\u001b[0m image \u001b[38;5;241m=\u001b[39m transform(image)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# Add batch dimension\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m()  \u001b[38;5;66;03m# Set model to evaluation mode\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():  \u001b[38;5;66;03m# Disable gradient tracking during inference\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(image)  \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'collections.OrderedDict' object has no attribute 'eval'"
     ]
    }
   ],
   "source": [
    "# Define the transform to preprocess the images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Define a function to predict the class for a single image\n",
    "def predict_image(model, image_path, transform):\n",
    "    image = Image.open(image_path).convert('L')  # Ensure the image is grayscale\n",
    "    image = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    with torch.no_grad():  # Disable gradient tracking during inference\n",
    "        outputs = model(image)  # Forward pass\n",
    "        _, predicted = torch.max(outputs, 1)  # Get predicted label\n",
    "    return predicted.item()\n",
    "\n",
    "# Path to the folder containing testing images\n",
    "test_folder = location + 'test_images/test_images'\n",
    "\n",
    "# Initialize model\n",
    "num_classes = 3  # Update with the number of classes in your dataset\n",
    "model = PneumoniaModel(num_classes=num_classes)\n",
    "\n",
    "# Try to load the model state dictionary\n",
    "try:\n",
    "    state_dict = torch.load(model_save_path)\n",
    "    model.load_state_dict(state_dict)\n",
    "    print(\"Loaded model state dictionary successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading the model state dictionary: {e}\")\n",
    "\n",
    "# Iterate over testing images and make predictions\n",
    "predictions = []\n",
    "file_names = []\n",
    "for file_name in os.listdir(test_folder):\n",
    "    image_path = os.path.join(test_folder, file_name)\n",
    "    predicted_label = predict_image(model, image_path, transform)\n",
    "    predictions.append(predicted_label)\n",
    "    file_names.append(file_name)\n",
    "\n",
    "# Create a DataFrame with file names and predicted labels\n",
    "results_df = pd.DataFrame({'file_name': file_names, 'class_id': predictions})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "results_df.to_csv(location + 'results/labels_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transform to preprocess the images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Define a function to predict the class for a single image\n",
    "def predict_image(model, image_path, transform):\n",
    "    image = Image.open(image_path).convert('L')  # Ensure the image is grayscale\n",
    "    image = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    with torch.no_grad():  # Disable gradient tracking during inference\n",
    "        outputs = model(image)  # Forward pass\n",
    "        _, predicted = torch.max(outputs, 1)  # Get predicted label\n",
    "    return predicted.item()\n",
    "\n",
    "# Load the trained model\n",
    "model_save_path = location + \"models/pneumonia_model_v1.pth\"\n",
    "num_classes = 3  # Update with the number of classes in your dataset\n",
    "\n",
    "# Define the model architecture and load the state dictionary\n",
    "class PneumoniaModel(pl.LightningModule):\n",
    "    def __init__(self, num_classes=3):\n",
    "        super(PneumoniaModel, self).__init__()\n",
    "        self.model = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "        self.model.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "model = PneumoniaModel(num_classes=num_classes)\n",
    "model.load_state_dict(torch.load(model_save_path))\n",
    "\n",
    "# Path to the folder containing testing images\n",
    "test_folder = location + 'test_images/test_images'\n",
    "\n",
    "# Iterate over testing images and make predictions\n",
    "predictions = []\n",
    "file_names = []\n",
    "for file_name in os.listdir(test_folder):\n",
    "    image_path = os.path.join(test_folder, file_name)\n",
    "    predicted_label = predict_image(model, image_path, transform)\n",
    "    predictions.append(predicted_label)\n",
    "    file_names.append(file_name)\n",
    "\n",
    "# Create a DataFrame with file names and predicted labels\n",
    "results_df = pd.DataFrame({'file_name': file_names, 'class_id': predictions})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "results_df.to_csv(location + 'results/labels_test.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
