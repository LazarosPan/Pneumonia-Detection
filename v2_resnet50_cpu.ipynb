{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lazaros/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import os\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor\n",
    "import torch\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "import multiprocessing\n",
    "\n",
    "num_cpu_cores = multiprocessing.cpu_count()\n",
    "num_cpu_cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_id\n",
      "1     762\n",
      "0    1773\n",
      "2    1793\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# to read .csv files from another directory\n",
    "location = \"detect-pneumonia-spring-2024/\" # \"/<path>\"\n",
    "\n",
    "df = pd.read_csv(location + \"labels_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    epochs = 100, \n",
    "    accelerator = 'cuda',\n",
    "    target_images_per_class = 10000\n",
    "else:\n",
    "    epochs = 10\n",
    "    accelerator = 'cpu',\n",
    "    target_images_per_class = 5000\n",
    "\n",
    "# Get the count of images in each class\n",
    "class_counts = df['class_id'].value_counts()\n",
    "# Calculate the number of additional images needed for each class\n",
    "additional_images_needed = target_images_per_class - class_counts\n",
    "print(additional_images_needed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 224, 224]) torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "# Define the augmentation function using OpenCV\n",
    "def augment_image(image):\n",
    "    # Random rotation\n",
    "    angle = np.random.uniform(-10, 10)\n",
    "    M = cv2.getRotationMatrix2D((image.shape[1] // 2, image.shape[0] // 2), angle, 1)\n",
    "    image = cv2.warpAffine(image, M, (image.shape[1], image.shape[0]))\n",
    "\n",
    "    # Random width and height shift\n",
    "    tx = np.random.uniform(-0.1, 0.1) * image.shape[1]\n",
    "    ty = np.random.uniform(-0.1, 0.1) * image.shape[0]\n",
    "    M = np.float32([[1, 0, tx], [0, 1, ty]])\n",
    "    image = cv2.warpAffine(image, M, (image.shape[1], image.shape[0]))\n",
    "\n",
    "    # Random shear\n",
    "    shear_factor = np.random.uniform(-0.2, 0.2)\n",
    "    M = np.float32([[1, shear_factor, 0], [0, 1, 0]])\n",
    "    image = cv2.warpAffine(image, M, (image.shape[1], image.shape[0]))\n",
    "\n",
    "    # Random zoom\n",
    "    zx, zy = np.random.uniform(0.9, 1.1, 2)\n",
    "    image = cv2.resize(image, None, fx=zx, fy=zy, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    # Random horizontal flip\n",
    "    if np.random.rand() < 0.5:\n",
    "        image = cv2.flip(image, 1)\n",
    "    \n",
    "    return image\n",
    "\n",
    "# Define the custom dataset\n",
    "class PneumoniaDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None, target_images_per_class=10000):\n",
    "        self.annotations = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.target_images_per_class = target_images_per_class\n",
    "        \n",
    "        # Calculate the number of images needed for each class\n",
    "        self.class_counts = self.annotations['class_id'].value_counts()\n",
    "        self.additional_images_needed = target_images_per_class - self.class_counts\n",
    "\n",
    "        # Create lists of images per class\n",
    "        self.image_paths_by_class = {class_id: [] for class_id in self.additional_images_needed.index}\n",
    "        for idx, row in self.annotations.iterrows():\n",
    "            self.image_paths_by_class[row['class_id']].append(row['file_name'])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.target_images_per_class * len(self.additional_images_needed)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Determine the class and the specific image index within that class\n",
    "        class_id = idx // self.target_images_per_class\n",
    "        img_idx = idx % self.target_images_per_class\n",
    "        \n",
    "        if img_idx < self.class_counts[class_id]:\n",
    "            # Original image\n",
    "            img_name = self.image_paths_by_class[class_id][img_idx]\n",
    "            img_path = os.path.join(self.root_dir, img_name)\n",
    "            image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        else:\n",
    "            # Augmented image\n",
    "            img_name = np.random.choice(self.image_paths_by_class[class_id])\n",
    "            img_path = os.path.join(self.root_dir, img_name)\n",
    "            image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            image = augment_image(image)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        label = class_id\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Create the dataset and dataloader\n",
    "dataset = PneumoniaDataset(\n",
    "    csv_file= location + 'labels_train.csv',\n",
    "    root_dir= location + 'train_images/train_images',\n",
    "    transform=transform,\n",
    "    target_images_per_class= target_images_per_class\n",
    ")\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=100, shuffle=False, num_workers= num_cpu_cores, pin_memory=True, persistent_workers=True)\n",
    "\n",
    "# Example of iterating through the dataloader\n",
    "for images, labels in dataloader:\n",
    "    print(images.shape, labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PneumoniaModel(pl.LightningModule):\n",
    "    def __init__(self, num_classes=3):\n",
    "        super(PneumoniaModel, self).__init__()\n",
    "        self.model = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "        self.model.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "        outputs = self(images)\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return Adam(self.parameters(), lr=1e-4)\n",
    "    \n",
    "# Define callbacks\n",
    "early_stopping_callback = EarlyStopping(monitor='train_loss', patience=3, verbose=True, mode='min')\n",
    "lr_monitor = LearningRateMonitor(logging_interval='epoch')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "2024-05-29 13:03:40.428941: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-29 13:03:40.526036: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-29 13:03:40.950271: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-29 13:03:43.213360: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\n",
      "  | Name  | Type   | Params\n",
      "---------------------------------\n",
      "0 | model | ResNet | 23.5 M\n",
      "---------------------------------\n",
      "23.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.032    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 90/90 [29:37<00:00,  0.05it/s, v_num=5]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 90/90 [29:39<00:00,  0.05it/s, v_num=5]\n"
     ]
    }
   ],
   "source": [
    "model = PneumoniaModel()\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=epochs, accelerator=accelerator)\n",
    "trainer.fit(model, dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 10 epochs completed in 260 minutes and 38.2 seconds with intel i5 8400 with an accuract = 0.79109."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the directory and file name to save the model\n",
    "model_save_path = location + \"models/resnet50_v1_cpu.pth\"\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), model_save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model state dictionary successfully.\n"
     ]
    }
   ],
   "source": [
    "# Define the transform to preprocess the images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Define a function to predict the class for a single image\n",
    "def predict_image(model, image_path, transform):\n",
    "    image = Image.open(image_path).convert('L')  # Ensure the image is grayscale\n",
    "    image = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    with torch.no_grad():  # Disable gradient tracking during inference\n",
    "        outputs = model(image)  # Forward pass\n",
    "        _, predicted = torch.max(outputs, 1)  # Get predicted label\n",
    "    return predicted.item()\n",
    "\n",
    "# Path to the folder containing testing images\n",
    "test_folder = location + 'test_images/test_images'\n",
    "\n",
    "# Initialize model\n",
    "num_classes = 3  # Update with the number of classes in your dataset\n",
    "model = PneumoniaModel(num_classes=num_classes)\n",
    "\n",
    "# Try to load the model state dictionary\n",
    "try:\n",
    "    state_dict = torch.load(model_save_path)\n",
    "    model.load_state_dict(state_dict)\n",
    "    print(\"Loaded model state dictionary successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading the model state dictionary: {e}\")\n",
    "\n",
    "# Iterate over testing images and make predictions\n",
    "predictions = []\n",
    "file_names = []\n",
    "for file_name in os.listdir(test_folder):\n",
    "    image_path = os.path.join(test_folder, file_name)\n",
    "    predicted_label = predict_image(model, image_path, transform)\n",
    "    predictions.append(predicted_label)\n",
    "    file_names.append(file_name)\n",
    "\n",
    "# Create a DataFrame with file names and predicted labels\n",
    "results_df = pd.DataFrame({'file_name': file_names, 'class_id': predictions})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "results_df.to_csv(location + 'results/labels_test_cpu_v1.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
